# Titanic Data Cleaning, EDA, and Predictive Modeling

##  Project Overview
This project focuses on cleaning and preprocessing the Titanic dataset, conducting exploratory data analysis (EDA), and training a machine learning model using the GradientBoostingClassifier. The goal is to prepare high-quality data and build a predictive model for passenger survival.

---

##  Objective
- Clean and preprocess raw Titanic data by handling missing values, duplicates, and inconsistencies.
- Normalize or standardize numerical columns to prepare data for analysis.
- Visualize key relationships and distributions in the dataset.
- Train a classification model to predict survival using cleaned and transformed features.

---

##  Problem Statement
Raw data often contains missing values, duplicates, and inconsistent formats that affect the reliability of any analysis or model. Effective cleaning and preprocessing are essential to ensure data quality and extract meaningful insights.

---

##  Tasks Covered

### 1. Data Cleaning & Preprocessing
- Handle missing values based on threshold percentages.
- Drop or fill columns and rows appropriately.
- Remove duplicate records.
- Normalize numerical columns using standardization techniques.

### 2. Exploratory Data Analysis (EDA)
- Visualize feature distributions using histograms, box plots, and pair plots.
- Analyze correlation and feature influence on survival.
- Check skewness and kurtosis of numeric features.

### 3. Feature Engineering
- Label encode categorical features.
- Scale numerical features.

### 4. Model Building
- Train a `GradientBoostingClassifier` on the processed dataset.
- Evaluate model performance using a confusion matrix and accuracy scores.
- Extract and visualize feature importances.

---

##  Results
- Successfully cleaned the Titanic dataset.
- Created visualizations to understand feature distributions and correlations.
- Built a Gradient Boosting model with good accuracy.
- Identified key features influencing survival prediction.

---

##  Conclusion
This project demonstrates the full pipeline of:
- Preparing real-world data through cleaning and preprocessing,
- Conducting effective EDA,
- Engineering meaningful features, and
- Building an interpretable and accurate machine learning model.

---

##  Tools & Libraries Used Video link
- Python
- Pandas
- NumPy
- Matplotlib & Seaborn
- Scikit-learn

---


##  Dataset Source
- [Titanic Dataset â€“ Kaggle](https://www.kaggle.com/competitions/titanic/data)

---
